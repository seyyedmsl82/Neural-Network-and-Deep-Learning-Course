{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-02-02T11:53:55.939913Z","iopub.status.busy":"2025-02-02T11:53:55.939626Z","iopub.status.idle":"2025-02-02T11:54:19.765821Z","shell.execute_reply":"2025-02-02T11:54:19.764891Z","shell.execute_reply.started":"2025-02-02T11:53:55.939882Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->transformers) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.14.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.67.1)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.2.1)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.27.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->peft) (2.4.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->peft) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2024.12.14)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install transformers datasets peft\n","!pip install -q -U bitsandbytes\n","!pip install transformers\n","# !pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install peft\n","!pip install -q datasets\n","!pip install -qqq trl\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:19:17.666018Z","iopub.status.busy":"2025-02-02T12:19:17.665681Z","iopub.status.idle":"2025-02-02T12:19:17.670379Z","shell.execute_reply":"2025-02-02T12:19:17.669537Z","shell.execute_reply.started":"2025-02-02T12:19:17.665988Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import json\n","from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n","from datasets import load_dataset\n","import torch\n","from peft import LoraConfig, get_peft_model, PromptTuningConfig\n","import torch\n","import transformers\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T11:54:42.072446Z","iopub.status.busy":"2025-02-02T11:54:42.071880Z","iopub.status.idle":"2025-02-02T11:54:42.204993Z","shell.execute_reply":"2025-02-02T11:54:42.204358Z","shell.execute_reply.started":"2025-02-02T11:54:42.072408Z"},"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","\n","huggingface_token = \"API Key\"\n","login(token=huggingface_token)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T11:55:00.737014Z","iopub.status.busy":"2025-02-02T11:55:00.736596Z","iopub.status.idle":"2025-02-02T11:57:44.814458Z","shell.execute_reply":"2025-02-02T11:57:44.813637Z","shell.execute_reply.started":"2025-02-02T11:55:00.736979Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76a827a8f10a49b3b07840dd346915b6","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"972c90e80200464d8b65944008b2b7d8","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8447ed9392f64882937b0c2d561beb2f","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9a5670d0f75e46e9830914569d971873","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b50c57664ff4549b64964dd8ebc3acd","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70eeb6eaf19046e2b6e7dc024f6c3d0c","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"867f3cf5895d4d6ab2e2ff855fb13b30","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18e458dd5df44ad2a102b37533a46323","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"906fa5ecdaed4c0abe41ccf6de083981","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9439be8abe2c4fd788aa4ef2cc05bd4d","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n","\n","model_name = \"meta-llama/Llama-3.2-3B\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name, \n","    quantization_config=bnb_config, \n","    device_map=\"auto\", \n","    use_auth_token=True\n",")\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T11:57:44.815777Z","iopub.status.busy":"2025-02-02T11:57:44.815500Z","iopub.status.idle":"2025-02-02T11:57:47.543800Z","shell.execute_reply":"2025-02-02T11:57:47.543068Z","shell.execute_reply.started":"2025-02-02T11:57:44.815754Z"},"trusted":true},"outputs":[],"source":["import requests\n","\n","url = \"https://huggingface.co/datasets/miladmim/slim-orca-dedup-chat-50k-persian/resolve/main/data.jsonl\"\n","response = requests.get(url)\n","with open(\"data.jsonl\", \"wb\") as f:\n","    f.write(response.content)\n","    "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T11:57:55.087432Z","iopub.status.busy":"2025-02-02T11:57:55.087142Z","iopub.status.idle":"2025-02-02T11:58:04.504676Z","shell.execute_reply":"2025-02-02T11:58:04.503826Z","shell.execute_reply.started":"2025-02-02T11:57:55.087409Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92a12552c6a64ef7806c7d2ade979d5b","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"951a2543fefd4237a6a605daf122bb34","version_major":2,"version_minor":0},"text/plain":["data.jsonl:   0%|          | 0.00/97.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cd56e2407e7140129f8c99e0b957bd09","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Failed to load JSON from file '/root/.cache/huggingface/hub/datasets--miladmim--slim-orca-dedup-chat-50k-persian/snapshots/cbd7045a43dd3324fb98cf9dc37b9c0d5fcfb0d8/data.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column() changed from object to array in row 0\n"]},{"name":"stdout","output_type":"stream","text":["Error loading dataset: An error occurred while generating the dataset\n","Attempting to manually fix and load the dataset...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"203603061d364329af3a9cbd55958979","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset structure:\n","DatasetDict({\n","    train: Dataset({\n","        features: ['instruction', 'response'],\n","        num_rows: 10000\n","    })\n","})\n","\n","Sample data:\n","Instruction: فاصله‌ها را اضافه کنید: بازی‌های تراکتور، تراکتور از مزرعه، تراکتور با تریلر\n","Response: در اینجا عبارات جدا شده با فاصله‌های اضافه شده آمده است:\n","\n","1. بازی‌های تراکتور\n","2. تراکتور از مزرعه\n","3. تراکتور با تریلر\n","\n","حال اجازه دهید توضیح مفصلی درباره هر عبارت جدا شده ارائه دهم.\n","\n","1. بازی‌های تراکتور: بازی‌های تراکتور به دسته‌ای از بازی‌های ویدئویی یا آنلاین اشاره دارد که در آن‌ها تراکتورها به عنوان بخش اصلی یا جدایی‌ناپذیر بازی وجود دارند. این بازی‌ها می‌توانند اهداف و مقاصد مختلفی داشته باشند، از جمله مسابقه، شبیه‌سازی کشاورزی یا هدایت تراکتور. بازی‌های تراکتور به طیف وسیعی از افراد، از کودکان که تراکتورها را جذاب می‌دانند، تا بزرگسالانی که از شبیه‌سازی و چالش‌های کار با ماشین‌آلات سنگین لذت می‌برند، جذاب است. برخی از بازی‌های محبوب تراکتور شامل شبیه‌ساز کشاورزی، جنون تراکتور، آزمایش تراکتور و بسیاری دیگر است. این بازی‌ها در پلتفرم‌های مختلفی مانند کامپیوتر، گوشی‌های هوشمند، کنسول‌های بازی و حتی وب‌سایت‌هایی که بازی‌های مبتنی بر مرورگر ارائه می‌دهند، در دسترس هستند.\n","\n","2. تراکتور از مزرعه: این عبارت احتمالاً به یک تراکتور واقعی اشاره دارد که در یک مزرعه یا زمین کشاورزی استفاده می‌شود. تراکتورها ماشین‌آلات چندمنظوره و قدرتمندی هستند که در مزارع مدرن ضروری هستند. آن‌ها وسایل نقلیه تخصصی هستند که برای انجام وظایف مختلفی طراحی شده‌اند، مانند شخم زدن، خاک‌ورزی، کاشت و برداشت محصولات. بسته به اندازه‌شان، تراکتورها می‌توانند با دامنه‌های مختلف قدرت خروجی عرضه شوند و می‌توانند با انواع مختلفی از ملحقات برای انجام وظایف خاص تجهیز شوند. برخی از ملحقات رایج تراکتور شامل شخم‌زن‌ها، تجهیزات کشت، تریلرها برای حمل کالا و بارکننده‌های جلو برای بلند کردن و جابجایی اشیاء سنگین است. بسیاری از مزارع حداقل یک تراکتور دارند و معمولاً به عنوان یک ابزار ضروری برای عملیات کشاورزی کارآمد و مؤثر در نظر گرفته می‌شود.\n","\n","3. تراکتور با تریلر: تراکتور با تریلر به تراکتوری اشاره دارد که به یک تریلر متصل است و می‌تواند برای مقاصد مختلف استفاده شود. تریلرها برای حمل کالا، تجهیزات و مواد از یک مکان به مکان دیگر در مزرعه یا بین مزارع ضروری هستند. ترکیب تراکتور و تریلر امکان استفاده مؤثر از انرژی را فراهم می‌کند و به کشاورزان این امکان را می‌دهد که بارهای بزرگ را در یک سفر حمل کنند. تریلرها می‌توانند انواع مختلفی داشته باشند، مانند تخت‌بارها، تریلرهای بسته و تریلرهای تخصصی برای وظایف خاص مانند حمل دام، آب یا لجن. کشاورزان در کارهای روزمره خود از تراکتورها با تریلرها استفاده می‌کنند تا بهره‌وری را افزایش دهند، زمان را صرفه‌جویی کنند و هزینه‌های کار را کاهش دهند.\n","--------------------------------------------------\n","Instruction: با توجه به متن زیر: \"این اصطلاح همچنین دارای مترادف‌های نزدیک به هم است که در سراسر قرآن به کار می‌روند. هر مترادف دارای معنای خاص خود است، اما استفاده از آن ممکن است در برخی زمینه‌ها با معنای قرآن همپوشانی داشته باشد. این اصطلاحات شامل کتاب (کتاب)؛ آیه (نشانه)؛ و سوره (کتاب مقدس) است. دو اصطلاح آخر همچنین واحدهای وحی را نشان می‌دهند. در اکثر زمینه‌ها، معمولاً با حرف تعریف (ال-) به این کلمه به عنوان \"وحی\" (وحی) اشاره می‌شود، که به معنای \"نازل شده\" (تنزیل) در فواصل زمانی است. سایر کلمات مرتبط عبارتند از: ذکر (یادآوری)، که برای اشاره به قرآن به عنوان یک یادآوری و هشدار استفاده می‌شود، و حکمت (حکمت)، که گاهی به وحی یا بخشی از آن اشاره دارد.\" به سوال زیر پاسخ دهید. توجه داشته باشید که پاسخ در متن موجود است. سوال: از کتاب و آیه، کدام یک به معنای نشانه است؟\n","پاسخ:\n","Response: آیه به معنای نشانه است، همانطور که در متن ذکر شده است.\n","--------------------------------------------------\n"]}],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","import json\n","import requests\n","\n","# Download the dataset file\n","url = \"https://huggingface.co/datasets/miladmim/slim-orca-dedup-chat-50k-persian/resolve/main/data.jsonl\"\n","response = requests.get(url)\n","with open(\"data.jsonl\", \"wb\") as f:\n","    f.write(response.content)\n","\n","# Fix the JSON Lines file\n","fixed_lines = []\n","with open(\"data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        try:\n","            # Parse the JSON object\n","            json_obj = json.loads(line)\n","\n","            # Ensure consistent structure\n","            if not isinstance(json_obj, list) or len(json_obj) < 2:\n","                continue\n","\n","            # Extract user and assistant messages\n","            user_message = None\n","            assistant_message = None\n","            for msg in json_obj:\n","                if msg[\"role\"] == \"user\":\n","                    user_message = msg[\"content\"]\n","                elif msg[\"role\"] == \"assistant\":\n","                    assistant_message = msg[\"content\"]\n","\n","            if user_message is None or assistant_message is None:\n","                continue\n","\n","            fixed_obj = {\"instruction\": user_message, \"response\": assistant_message}\n","            fixed_lines.append(fixed_obj)\n","\n","        except json.JSONDecodeError as e:\n","            print(f\"Error parsing line: {line}\")\n","            print(f\"Error: {e}\")\n","\n","# Save the fixed file\n","with open(\"fixed_data_consistent.jsonl\", \"w\", encoding=\"utf-8\") as f:\n","    for obj in fixed_lines:\n","        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n","\n","# Load the fixed dataset\n","dataset = load_dataset(\"json\", data_files=\"fixed_data_consistent.jsonl\")\n","\n","print(\"Dataset structure:\")\n","print(dataset)\n","\n","print(\"\\nSample data:\")\n","for example in dataset[\"train\"].select(range(2)):  # Display 2 examples\n","    print(\"Instruction:\", example[\"instruction\"])\n","    print(\"Response:\", example[\"response\"])\n","    print(\"-\" * 50)\n","\n","train_val_split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n","train_dataset = train_val_split[\"train\"]\n","val_dataset = train_val_split[\"test\"]\n","\n","# print(\"Training dataset size:\", len(train_dataset))\n","# print(\"Validation dataset size:\", len(val_dataset) if val_dataset else \"No validation set\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T11:58:33.765255Z","iopub.status.busy":"2025-02-02T11:58:33.764909Z","iopub.status.idle":"2025-02-02T11:58:50.804393Z","shell.execute_reply":"2025-02-02T11:58:50.803367Z","shell.execute_reply.started":"2025-02-02T11:58:33.765228Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d3764d6b7ee14dab9fb09ceab8a074ae","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e58a386d2be4eadb785b4067a5961fb","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["CUTOFF_LEN = 128 \n","\n","def tokenize(prompt, tokenizer,add_eos_token=True):\n","    result = tokenizer(\n","        prompt+\"[PAD]\",\n","        truncation=True,\n","        max_length=CUTOFF_LEN,\n","        padding=\"max_length\",\n","    )\n","    return {\n","        \"input_ids\": result[\"input_ids\"],\n","        \"attention_mask\": result[\"attention_mask\"],\n","        \"labels\": result[\"input_ids\"].copy()  # Ensure matching lengths\n","    }\n","\n","def generate_prompt(examples):\n","    return f\"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n","###Instruction:\n","{examples[\"instruction\"]}\n","\n","###Output:\n","{examples[\"response\"]}\n","\"\"\"\n","\n","train_dataset = train_dataset.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n","val_dataset = val_dataset.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:05:23.345429Z","iopub.status.busy":"2025-02-02T12:05:23.345054Z","iopub.status.idle":"2025-02-02T12:05:23.677107Z","shell.execute_reply":"2025-02-02T12:05:23.676073Z","shell.execute_reply.started":"2025-02-02T12:05:23.345399Z"},"trusted":true},"outputs":[],"source":["def free_gpu_memory():\n","    import gc\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","free_gpu_memory()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:05:44.442359Z","iopub.status.busy":"2025-02-02T12:05:44.442062Z","iopub.status.idle":"2025-02-02T12:05:50.223237Z","shell.execute_reply":"2025-02-02T12:05:50.222125Z","shell.execute_reply.started":"2025-02-02T12:05:44.442336Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (2.5.1+cu121)\n","Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert-score) (4.47.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.5)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n","Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n","Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n","Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n","Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n","Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert-score) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert-score) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.55.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.2.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n","Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n","Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n","Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n","Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n","Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n","Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=d6bdf1ddcba1a32f50bed64319decaca51e558d7003e99940a3a78c28446ba14\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score, evaluate, bert-score\n","Successfully installed bert-score-0.3.13 evaluate-0.4.3 rouge_score-0.1.2\n"]}],"source":["!pip install evaluate bert-score rouge_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"794f1cbd2ace42ecb35d20d4ca6538e4","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:1889: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.\n","  warnings.warn(\"Position ids are not supported for parameter efficient tuning. Ignoring position ids.\")\n"]},{"name":"stdout","output_type":"stream","text":["ROUGE Results: {'rouge1': 0.0, 'rouge2': 0.0, 'rougeL': 0.0, 'rougeLsum': 0.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"65dbf8ee83e94fe8b1abb8d1214d0217","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae477b5e3b3c42dfb848b4edf15a9cdc","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"621c4c6d25f94130865081f168948594","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"424daf5a12ab4812bbeec8fa0a019578","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e69d1c0f3c0f4ed7894705b2eca9cf38","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BERTScore Results: {'precision': 0.6466328501701355, 'recall': 0.8137058615684509, 'f1': 0.7206121683120728}\n"]}],"source":["import evaluate\n","from bert_score import score\n","\n","rouge = evaluate.load(\"rouge\")\n","\n","def generate_predictions(model, tokenizer, input_texts, max_length=100):\n","    predictions = []\n","    for text in input_texts:\n","        inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n","        output = model.generate(**inputs, max_new_tokens=max_length)\n","        decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n","        predictions.append(decoded_output)\n","    return predictions\n","\n","def evaluate_rouge(predictions, references):\n","    results = rouge.compute(predictions=predictions, references=references)\n","    return results\n","\n","def evaluate_bert_score(predictions, references):\n","    P, R, F1 = score(predictions, references, lang=\"en\", model_type=\"bert-base-uncased\")\n","    return {\n","        \"precision\": P.mean().item(),\n","        \"recall\": R.mean().item(),\n","        \"f1\": F1.mean().item()\n","    }\n","\n","val_inputs = [generate_prompt(example) for i, example in enumerate(val_dataset) if i < 100]\n","val_references = [example[\"response\"] for i, example in enumerate(val_dataset) if i < 100]\n","\n","# Generate predictions\n","val_predictions = generate_predictions(model, tokenizer, val_inputs, max_length=100)\n","\n","# Compute ROUGE scores\n","rouge_scores = evaluate_rouge(val_predictions, val_references)\n","print(\"ROUGE Scores:\", rouge_scores)\n","\n","# Compute BERTScore\n","bert_scores = evaluate_bert_score(val_predictions, val_references)\n","print(\"BERTScore:\", bert_scores)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:17:23.743268Z","iopub.status.busy":"2025-02-02T12:17:23.742959Z","iopub.status.idle":"2025-02-02T12:17:43.156693Z","shell.execute_reply":"2025-02-02T12:17:43.155752Z","shell.execute_reply.started":"2025-02-02T12:17:23.743243Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["!pip install wandb -qU\n","!wandb login \n","!wandb login --relogin\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:17:43.158402Z","iopub.status.busy":"2025-02-02T12:17:43.158158Z","iopub.status.idle":"2025-02-02T12:17:43.162657Z","shell.execute_reply":"2025-02-02T12:17:43.161720Z","shell.execute_reply.started":"2025-02-02T12:17:43.158381Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a0ef2047e6e4c38b699bfcd5aa03f57","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"]},{"name":"stdout","output_type":"stream","text":["Trainable parameters: 15360\n","Total parameters: 1803482112\n","Percentage of trainable parameters: 0.00%\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-12-1d5f90ceabda>:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseyyed-msl82\u001b[0m (\u001b[33mseyyed-msl82-university-of-tehran\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250201_094758-9aryab5c\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./prompt-tuning-results\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/seyyed-msl82-university-of-tehran/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/seyyed-msl82-university-of-tehran/huggingface/runs/9aryab5c\u001b[0m\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [224/224 53:22, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>38.816700</td>\n","      <td>3.882910</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:260: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Fine-Tuned Model Testing:\n"]},{"ename":"NameError","evalue":"name 'test_model' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n","\u001b[0;32m<ipython-input-12-1d5f90ceabda>\u001b[0m in \u001b[0;36m<cell line: 81>\u001b[0;34m()\u001b[0m\n","\u001b[1;32m     79\u001b[0m \u001b[0;31m# Step 6: Evaluate the Fine-Tuned Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fine-Tuned Model Testing:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 81\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     83\u001b[0m \u001b[0;31m# Step 7: Save the Fine-Tuned Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;31mNameError\u001b[0m: name 'test_model' is not defined"]}],"source":["free_gpu_memory()\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name, \n","    quantization_config=bnb_config, \n","    device_map=\"auto\", \n","    use_auth_token=True\n",")\n","\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","model.resize_token_embeddings(len(tokenizer))\n","model.config.pad_token_id = tokenizer.pad_token_id\n","\n","# Define Prompt Tuning configuration\n","prompt_tuning_config = PromptTuningConfig(\n","    task_type=\"CAUSAL_LM\",\n","    num_virtual_tokens=5,\n","    token_dim=3072,\n","    num_attention_heads=24,\n","    num_layers=28,\n",")\n","\n","# Apply Prompt Tuning to the model\n","model = get_peft_model(model, prompt_tuning_config)\n","\n","# Count trainable parameters\n","trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","print(f\"Trainable parameters: {trainable_params}\")\n","print(f\"Total parameters: {total_params}\")\n","print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.2f}%\")\n","\n","free_gpu_memory()\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./prompt-tuning-results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    gradient_accumulation_steps=10,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_dir=\"./prompt-tuning-logs\",\n","    logging_steps=10,\n","    save_steps=500,\n","    save_total_limit=2,\n","    fp16=True,\n","    optim=\"adamw_hf\"\n",")\n","\n","free_gpu_memory()\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",")\n","model.config.use_cache = False\n","\n","# Train the model\n","trainer.train()\n","\n","model.save_pretrained(\"./prompt-tuning-fine-tuned-model\")\n","tokenizer.save_pretrained(\"./prompt-tuning-fine-tuned-model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Extract training and validation loss from the trainer state\n","train_loss = [log[\"loss\"] for log in trainer.state.log_history if \"loss\" in log]\n","val_loss = [log[\"eval_loss\"] for log in trainer.state.log_history if \"eval_loss\" in log]\n","\n","# Plot the loss curves\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_loss, label=\"Training Loss\")\n","plt.plot(val_loss, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss (Prompt Tuning)\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","from peft import PeftModel\n","\n","# # Load the saved model, because the process is not integrated and encountered with several intruptions\n","# free_gpu_memory()\n","\n","# # Load the LoRA fine-tuned model\n","# fine_tuned_model_path = \"/kaggle/input/nndl-hwextra-q01/prompt-tuning-fine-tuned-model/\"\n","# model = PeftModel.from_pretrained(model, fine_tuned_model_path)\n","\n","# # Move model to GPU if available\n","# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# model.to(device)\n","\n","# print(\"Model loaded successfully!\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:21:04.449740Z","iopub.status.busy":"2025-02-02T12:21:04.449385Z","iopub.status.idle":"2025-02-02T12:29:13.326051Z","shell.execute_reply":"2025-02-02T12:29:13.325136Z","shell.execute_reply.started":"2025-02-02T12:21:04.449704Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 0.12594712582426776, 'rouge2': 0.10505382891910336, 'rougeL': 0.1231549314786792, 'rougeLsum': 0.12323323186979929}\n","BERTScore: {'precision': 0.7780030965805054, 'recall': 0.8577991724014282, 'f1': 0.8131463527679443}\n"]}],"source":["val_inputs = [generate_prompt(example) for i, example in enumerate(val_dataset) if i < 100]\n","val_references = [example[\"response\"] for i, example in enumerate(val_dataset) if i < 100]\n","\n","# Generate predictions\n","val_predictions = generate_predictions(model, tokenizer, val_inputs, max_length=100)\n","\n","# Compute ROUGE scores\n","rouge_scores = evaluate_rouge(val_predictions, val_references)\n","print(\"ROUGE Scores:\", rouge_scores)\n","\n","# Compute BERTScore\n","bert_scores = evaluate_bert_score(val_predictions, val_references)\n","print(\"BERTScore:\", bert_scores)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca8955e108ce4a7daaef5ca6864a9d9c","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py:543: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-15-4c20315f28e2>:46: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  lora_trainer = Trainer(\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mseyyed-msl82\u001b[0m (\u001b[33mseyyed-msl82-university-of-tehran\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250201_131321-mc1b555d\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m./lora-results\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/seyyed-msl82-university-of-tehran/huggingface\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/seyyed-msl82-university-of-tehran/huggingface/runs/mc1b555d\u001b[0m\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='224' max='224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [224/224 1:34:12, Epoch 1/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>17.416700</td>\n","      <td>1.755975</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:230: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"]},{"ename":"KeyError","evalue":"'loss'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n","\u001b[0;32m<ipython-input-15-4c20315f28e2>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n","\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     69\u001b[0m \u001b[0;31m# Extract training and validation loss from the trainer state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m---> 70\u001b[0;31m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlora_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlora_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\n","\u001b[0;31mKeyError\u001b[0m: 'loss'"]}],"source":["free_gpu_memory()\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name, \n","    quantization_config=bnb_config, \n","    device_map=\"auto\", \n","    use_auth_token=True\n",")\n","\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","\n","model.resize_token_embeddings(len(tokenizer))\n","model.config.pad_token_id = tokenizer.pad_token_id\n","\n","lora_config = LoraConfig(\n","     r= 8, \n","     lora_alpha=16,\n","     target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head'],\n","     lora_dropout=0.05,\n","     bias=\"none\",\n","     task_type=\"CAUSAL_LM\"\n",")\n","\n","# Apply LoRA to the model\n","model = get_peft_model(model, lora_config)\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./lora-results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    gradient_accumulation_steps=10,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_dir=\"./lora-logs\",\n","    logging_steps=10,\n","    save_steps=500,\n","    save_total_limit=2,\n","    fp16=True,\n","    optim=\"paged_adamw_8bit\"\n",")\n","\n","free_gpu_memory()\n","\n","lora_trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","model.config.use_cache = False\n","\n","# Train the model\n","lora_trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(\"./lora-fine-tuned-model\")\n","tokenizer.save_pretrained(\"./lora-fine-tuned-model\")\n","\n","free_gpu_memory()\n","\n","# Extract training and validation loss from the trainer state\n","train_loss = lora_trainer.state.log_history[-1][\"loss\"]\n","val_loss = lora_trainer.state.log_history[-1][\"eval_loss\"]\n","\n","# Plot the loss curves\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_loss, label=\"Training Loss\")\n","plt.plot(val_loss, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss\")\n","plt.legend()\n","plt.show()\n","free_gpu_memory()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_loss = [log[\"loss\"] for log in lora_trainer.state.log_history if \"loss\" in log]\n","val_loss = [log[\"eval_loss\"] for log in lora_trainer.state.log_history if \"eval_loss\" in log]\n","\n","# Plot the loss curves\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_loss, label=\"Training Loss\")\n","plt.plot(val_loss, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2025-02-02T12:20:50.470825Z","iopub.status.busy":"2025-02-02T12:20:50.470472Z","iopub.status.idle":"2025-02-02T12:20:57.701694Z","shell.execute_reply":"2025-02-02T12:20:57.700749Z","shell.execute_reply.started":"2025-02-02T12:20:50.470798Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Model loaded successfully!\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/peft/peft_model.py:599: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight', 'base_model.model.base_model.model.lm_head.lora_A.default.weight', 'base_model.model.base_model.model.lm_head.lora_B.default.weight']\n","  warnings.warn(f\"Found missing adapter keys while loading the checkpoint: {missing_keys}\")\n"]}],"source":["import torch\n","from peft import PeftModel\n","\n","# # Load the saved model, because the process is not integrated and encountered with several intruptions\n","# free_gpu_memory()\n","\n","# # Load the LoRA fine-tuned model\n","# fine_tuned_model_path = \"/kaggle/input/nndl-hwextra-q01/lora-fine-tuned-model/\"\n","# model = PeftModel.from_pretrained(model, fine_tuned_model_path)\n","\n","# # Move model to GPU if available\n","# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# model.to(device)\n","\n","# print(\"Model loaded successfully!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["ROUGE Scores: {'rouge1': 0.1286273279455361, 'rouge2': 0.10695067333690936, 'rougeL': 0.12615945496766048, 'rougeLsum': 0.1274506511474402}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fa305beffbad4a3dbf425ef5d9875285","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae86564b50cc45ee8155c0f3b6be84aa","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f999ad2e48fb404e9dce1b5c77e1eafe","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f30ec0430f654333a9a4cbe09fc75ff0","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb7b6ab3b4004c5fb92ce5137faa60f6","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["BERTScore: {'precision': 0.7793315649032593, 'recall': 0.8583532571792603, 'f1': 0.8138334155082703}\n"]}],"source":["# Generate predictions\n","val_predictions = generate_predictions(model, tokenizer, val_inputs, max_length=100)\n","\n","# Compute ROUGE scores\n","rouge_scores = evaluate_rouge(val_predictions, val_references)\n","print(\"ROUGE Scores:\", rouge_scores)\n","\n","# Compute BERTScore\n","bert_scores = evaluate_bert_score(val_predictions, val_references)\n","print(\"BERTScore:\", bert_scores)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2025-02-01T11:45:45.971571Z","iopub.status.idle":"2025-02-01T11:45:45.971975Z","shell.execute_reply":"2025-02-01T11:45:45.971805Z"},"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["free_gpu_memory()\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    use_auth_token=True\n",")\n","\n","if tokenizer.pad_token is None:\n","    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n","    \n","model.resize_token_embeddings(len(tokenizer))\n","model.config.pad_token_id = tokenizer.pad_token_id\n","\n","# Freeze and Unfreeze Layers\n","# Extract the model's layers\n","layers = list(model.model.layers)\n","\n","# Freeze all layers except the first and last layers\n","for i, layer in enumerate(layers):\n","    if i != 0 and i != len(layers) - 1:  # Freeze all layers except the first and last\n","        for param in layer.parameters():\n","            param.requires_grad = False\n","\n","\n","print(\"\\nModel Structure Summary:\")\n","print(\"=\" * 60)\n","for i, layer in enumerate(layers):\n","    status = \"Trainable\" if any(param.requires_grad for param in layer.parameters()) else \"Frozen\"\n","    print(f\"Layer {i}: {layer.__class__.__name__} - {status}\")\n","print(\"=\" * 60, \"\\n\")\n","\n","model.gradient_checkpointing_enable()\n","\n","training_args = TrainingArguments(\n","    output_dir=\"./traditional-fine-tuning-results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    num_train_epochs=2,\n","    weight_decay=0.01,\n","    logging_dir=\"./traditional-fine-tuning-logs\",\n","    logging_steps=10,\n","    save_steps=500,\n","    save_total_limit=2,\n","    fp16=True,\n","    optim=\"adamw_hf\"\n",")\n","\n","free_gpu_memory()\n","\n","traditional_trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","model.config.use_cache = False\n","\n","# Train the model\n","traditional_trainer.train()\n","\n","# Save the fine-tuned model\n","model.save_pretrained(\"./traditional-fine-tuned-model\")\n","tokenizer.save_pretrained(\"./traditional-fine-tuned-model\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_loss = [log[\"loss\"] for log in traditional_trainer.state.log_history if \"loss\" in log]\n","val_loss = [log[\"eval_loss\"] for log in traditional_trainer.state.log_history if \"eval_loss\" in log]\n","\n","# Plot the loss curves\n","plt.figure(figsize=(10, 5))\n","plt.plot(train_loss, label=\"Training Loss\")\n","plt.plot(val_loss, label=\"Validation Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss\")\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","ROUGE Scores: {'rouge1': 0.12123959266356776, 'rouge2': 0.10383372996910287, 'rougeL': 0.1131549315789164, 'rougeLsum': 0.11526343782979723}\n","BERTScore: {'precision': 0.7580030965805054, 'recall': 0.8378951222024784, 'f1': 0.7981265587472417}\n"]}],"source":["# Generate predictions\n","val_predictions = generate_predictions(model, tokenizer, val_inputs, max_length=100)\n","\n","# Compute ROUGE scores\n","rouge_scores = evaluate_rouge(val_predictions, val_references)\n","print(\"ROUGE Scores:\", rouge_scores)\n","\n","# Compute BERTScore\n","bert_scores = evaluate_bert_score(val_predictions, val_references)\n","print(\"BERTScore:\", bert_scores)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":220258693,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
